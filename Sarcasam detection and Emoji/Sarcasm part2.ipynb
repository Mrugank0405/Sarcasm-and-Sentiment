{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7DRlZUYZlaV",
        "outputId": "c023e041-fe84-4be5-a5af-247ec890457a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting emoji\n",
            "  Downloading emoji-2.11.0-py2.py3-none-any.whl (433 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m433.8/433.8 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: emoji\n",
            "Successfully installed emoji-2.11.0\n"
          ]
        }
      ],
      "source": [
        "!pip install emoji"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uKP8v_smZx5Y"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gensim\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import string\n",
        "import random\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, GRU, LSTM, Bidirectional\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from keras.initializers import Constant\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import load_model\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBhv8g3zZ3hq",
        "outputId": "ce000192-1575-4372-8074-7a7c6c19a5c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected emojis: ['üòä', '‚ù§']\n"
          ]
        }
      ],
      "source": [
        "import emoji\n",
        "\n",
        "# Define emoji mappings\n",
        "positive_emojis = [\"üòä\", \"üòÑ\", \"ü•≥\",\"‚ù§Ô∏è\"]\n",
        "negative_emojis = [\"üò¢\", \"üò†\", \"üòû\"]\n",
        "neutral_emojis = [\"üòê\", \"üòë\", \"üò∂\"]\n",
        "\n",
        "# Function to detect emojis in text\n",
        "def detect_emojis(text):\n",
        "  emojis = []\n",
        "  for character in text:\n",
        "    if character in emoji.EMOJI_DATA:\n",
        "      emojis.append(character)\n",
        "  return emojis\n",
        "\n",
        "# Example usage\n",
        "text = \"I love Colgate but I don't like its taste üòä‚ù§Ô∏è\"\n",
        "detected_emojis = detect_emojis(text)\n",
        "print(\"Detected emojis:\", detected_emojis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-r1WjxvfanAH"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zB7hRADya1xk",
        "outputId": "53bbac2c-f38b-430c-bd61-85312700a385"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found TPU at: grpc://10.38.174.154:8470\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "try:\n",
        "    device_name = os.environ['COLAB_TPU_ADDR']\n",
        "    TPU_ADDRESS = 'grpc://' + device_name\n",
        "    print('Found TPU at: {}'.format(TPU_ADDRESS))\n",
        "except KeyError:\n",
        "    print('TPU not found')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AhVt9M5a53n",
        "outputId": "f6786697-747c-4b57-bd82-6a7c93034ca5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                        article_link  \\\n",
            "0  https://www.huffingtonpost.com/entry/versace-b...   \n",
            "1  https://www.huffingtonpost.com/entry/roseanne-...   \n",
            "2  https://local.theonion.com/mom-starting-to-fea...   \n",
            "3  https://politics.theonion.com/boehner-just-wan...   \n",
            "4  https://www.huffingtonpost.com/entry/jk-rowlin...   \n",
            "\n",
            "                                            headline  is_sarcastic  \n",
            "0  former versace store clerk sues over secret 'b...             0  \n",
            "1  the 'roseanne' revival catches up to our thorn...             0  \n",
            "2  mom starting to fear son's web series closest ...             1  \n",
            "3  boehner just wants wife to listen, not come up...             1  \n",
            "4  j.k. rowling wishes snape happy birthday in th...             0  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the JSON data using Pandas\n",
        "data_1 = pd.read_json(\"/content/Sarcasm_Headlines_Dataset.json\", lines=True)\n",
        "data_2 = pd.read_json(\"/content/Sarcasm_Headlines_Dataset_v2.json\", lines=True)\n",
        "\n",
        "# Combine the data into a single DataFrame\n",
        "data = pd.concat([data_1, data_2])\n",
        "\n",
        "# Preview the first few rows of the data\n",
        "print(data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yqKQavNYeSCD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb8afef7-8e53-4c4b-8504-a5ecfdfee255"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jcrmi8Q_eT50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90cbb967-1dba-4ee6-c1b7-b330a58d25e3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "55328"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "len(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45E9TWLHEH3S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0072d98a-a286-4ba0-dbe3-813c448683f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    29970\n",
            "1    25358\n",
            "Name: is_sarcastic, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "counts = data['is_sarcastic'].value_counts()\n",
        "print(counts)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c86HYa3YEKFF"
      },
      "outputs": [],
      "source": [
        "df = data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LJpv8dwwEQF3"
      },
      "outputs": [],
      "source": [
        "df = df.drop_duplicates()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_wdEhZeESTK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "1ee397a6-7906-4bac-e828-c023248c55d1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            article_link  \\\n",
              "0      https://www.huffingtonpost.com/entry/versace-b...   \n",
              "1      https://www.huffingtonpost.com/entry/roseanne-...   \n",
              "2      https://local.theonion.com/mom-starting-to-fea...   \n",
              "3      https://politics.theonion.com/boehner-just-wan...   \n",
              "4      https://www.huffingtonpost.com/entry/jk-rowlin...   \n",
              "...                                                  ...   \n",
              "28497  https://www.theonion.com/tyson-holds-contest-t...   \n",
              "28509  https://politics.theonion.com/increasingly-coc...   \n",
              "28520  https://www.theonion.com/cash-strapped-zuckerb...   \n",
              "28544  https://local.theonion.com/grocery-store-bar-a...   \n",
              "28589  https://www.theonion.com/study-83-of-marathon-...   \n",
              "\n",
              "                                                headline  is_sarcastic  \n",
              "0      former versace store clerk sues over secret 'b...             0  \n",
              "1      the 'roseanne' revival catches up to our thorn...             0  \n",
              "2      mom starting to fear son's web series closest ...             1  \n",
              "3      boehner just wants wife to listen, not come up...             1  \n",
              "4      j.k. rowling wishes snape happy birthday in th...             0  \n",
              "...                                                  ...           ...  \n",
              "28497  tyson holds contest to let fans submit new ide...             1  \n",
              "28509  increasingly cocky bernie sanders announces he...             1  \n",
              "28520  cash-strapped zuckerberg forced to sell 11 mil...             1  \n",
              "28544  grocery store bar actually has great little ha...             1  \n",
              "28589  study: 83% of marathon spectators only attend ...             1  \n",
              "\n",
              "[28617 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-be2b6963-b0ad-4403-8421-fda643a1efe7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article_link</th>\n",
              "      <th>headline</th>\n",
              "      <th>is_sarcastic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://www.huffingtonpost.com/entry/versace-b...</td>\n",
              "      <td>former versace store clerk sues over secret 'b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://www.huffingtonpost.com/entry/roseanne-...</td>\n",
              "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://local.theonion.com/mom-starting-to-fea...</td>\n",
              "      <td>mom starting to fear son's web series closest ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://politics.theonion.com/boehner-just-wan...</td>\n",
              "      <td>boehner just wants wife to listen, not come up...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://www.huffingtonpost.com/entry/jk-rowlin...</td>\n",
              "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28497</th>\n",
              "      <td>https://www.theonion.com/tyson-holds-contest-t...</td>\n",
              "      <td>tyson holds contest to let fans submit new ide...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28509</th>\n",
              "      <td>https://politics.theonion.com/increasingly-coc...</td>\n",
              "      <td>increasingly cocky bernie sanders announces he...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28520</th>\n",
              "      <td>https://www.theonion.com/cash-strapped-zuckerb...</td>\n",
              "      <td>cash-strapped zuckerberg forced to sell 11 mil...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28544</th>\n",
              "      <td>https://local.theonion.com/grocery-store-bar-a...</td>\n",
              "      <td>grocery store bar actually has great little ha...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28589</th>\n",
              "      <td>https://www.theonion.com/study-83-of-marathon-...</td>\n",
              "      <td>study: 83% of marathon spectators only attend ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>28617 rows √ó 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-be2b6963-b0ad-4403-8421-fda643a1efe7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-be2b6963-b0ad-4403-8421-fda643a1efe7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-be2b6963-b0ad-4403-8421-fda643a1efe7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4a912cb3-8727-45e8-bc11-5ab09114a4ab\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4a912cb3-8727-45e8-bc11-5ab09114a4ab')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4a912cb3-8727-45e8-bc11-5ab09114a4ab button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_24dc7909-aa86-4428-a710-eff80ff513f2\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_24dc7909-aa86-4428-a710-eff80ff513f2 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 28617,\n  \"fields\": [\n    {\n      \"column\": \"article_link\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 28617,\n        \"samples\": [\n          \"https://entertainment.theonion.com/christian-bale-loses-40-years-for-upcoming-movie-role-1833999023\",\n          \"https://www.huffingtonpost.com/entry/jon-stewart-911-responders_us_55f950bce4b0b48f67014d60\",\n          \"https://www.huffingtonpost.com/entry/inhofe-barbra-streisand_n_6261874.html\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"headline\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 28503,\n        \"samples\": [\n          \"facing fbi bank fraud investigation, bernie and jane sanders hire lawyers\",\n          \"impoverished kenyan bean picker can't wait to see what starbucks has to say about racial sensitivity\",\n          \"'stranger things' kids already look like winners on the golden globes red carpet\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_sarcastic\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r69wy_lfES1G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7d0cc48-9325-40d0-a570-8722450003ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sarcastic Data- 13633\n",
            "Non-Sarcastic Data- 14984\n"
          ]
        }
      ],
      "source": [
        "pos_data = df.loc[df['is_sarcastic'] == 1]\n",
        "nos_data = df.loc[df['is_sarcastic'] == 0]\n",
        "print(\"Sarcastic Data-\",len(pos_data))\n",
        "print(\"Non-Sarcastic Data-\",len(nos_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dRBmeIX0EVB2"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "\n",
        "    pattern = re.compile('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
        "    text = pattern.sub('', text)\n",
        "    text = \" \".join(filter(lambda x:x[0]!='@', text.split()))\n",
        "    emoji = re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001FFFF\"  # emoticons\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "\n",
        "    text = emoji.sub(r'', text)\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"i'm\", \"i am\", text)\n",
        "    text = re.sub(r\"he's\", \"he is\", text)\n",
        "    text = re.sub(r\"she's\", \"she is\", text)\n",
        "    text = re.sub(r\"that's\", \"that is\", text)\n",
        "    text = re.sub(r\"what's\", \"what is\", text)\n",
        "    text = re.sub(r\"where's\", \"where is\", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
        "    text = re.sub(r\"\\'re\", \" are\", text)\n",
        "    text = re.sub(r\"\\'d\", \" would\", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
        "    text = re.sub(r\"won't\", \"will not\", text)\n",
        "    text = re.sub(r\"don't\", \"do not\", text)\n",
        "    text = re.sub(r\"did't\", \"did not\", text)\n",
        "    text = re.sub(r\"can't\", \"can not\", text)\n",
        "    text = re.sub(r\"it's\", \"it is\", text)\n",
        "    text = re.sub(r\"couldn't\", \"could not\", text)\n",
        "    text = re.sub(r\"have't\", \"have not\", text)\n",
        "    text = re.sub(r\"[,.\\\"\\'!@#$%^&*(){}?/;`~:<>+=-]\", \"\", text)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WLtAyEs5EWw8"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.data.path.append('/content/nltk_data')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P4mtaUZOEZpu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f16a3c04-9a5d-42af-8c75-eb75ab582f12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('words')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DulxT8keE5eG"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "def CleanTokenize(df):\n",
        "    head_lines = list()\n",
        "    lines = df[\"headline\"].values.tolist()\n",
        "\n",
        "    for line in lines:\n",
        "        line = clean_text(line)\n",
        "        # tokenize the text\n",
        "        tokens = word_tokenize(line)\n",
        "        # remove puntuations\n",
        "        table = str.maketrans('', '', string.punctuation)\n",
        "        stripped = [w.translate(table) for w in tokens]\n",
        "        # remove non alphabetic characters\n",
        "        words = [word for word in stripped if word.isalpha()]\n",
        "        stop_words = set(stopwords.words(\"english\"))\n",
        "        # remove stop words\n",
        "        words = [w for w in words if not w in stop_words]\n",
        "        head_lines.append(words)\n",
        "    return head_lines\n",
        "\n",
        "head_lines = CleanTokenize(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WsvgSRfEE7zF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1425697-31bf-4aab-9bae-e18db7823a85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unique tokens -  28657\n",
            "vocab size - 28658\n"
          ]
        }
      ],
      "source": [
        "validation_split = 0.2\n",
        "max_length = 25\n",
        "\n",
        "\n",
        "tokenizer_obj = Tokenizer()\n",
        "tokenizer_obj.fit_on_texts(head_lines)\n",
        "sequences = tokenizer_obj.texts_to_sequences(head_lines)\n",
        "\n",
        "word_index = tokenizer_obj.word_index\n",
        "print(\"unique tokens - \",len(word_index))\n",
        "vocab_size = len(tokenizer_obj.word_index) + 1\n",
        "print('vocab size -', vocab_size)\n",
        "\n",
        "lines_pad = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
        "sentiment =  data['is_sarcastic'].values\n",
        "\n",
        "indices = np.arange(lines_pad.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "lines_pad = lines_pad[indices]\n",
        "sentiment = sentiment[indices]\n",
        "\n",
        "num_validation_samples = int(validation_split * lines_pad.shape[0])\n",
        "\n",
        "X_train_pad = lines_pad[:-num_validation_samples]\n",
        "y_train = sentiment[:-num_validation_samples]\n",
        "X_test_pad = lines_pad[-num_validation_samples:]\n",
        "y_test = sentiment[-num_validation_samples:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TQAuHMmgFJ8Q"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "loaded_model = tf.keras.models.load_model(\"/content/model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZFKcYo5oGI1_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7970d74-313f-4843-a07b-841f110b5109"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 325ms/step\n",
            "It's a sarcasm!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "def predict_sarcasm(s):\n",
        "    x_final = pd.DataFrame({\"headline\":[s]})\n",
        "    test_lines = CleanTokenize(x_final)\n",
        "    test_sequences = tokenizer_obj.texts_to_sequences(test_lines)\n",
        "    test_review_pad = pad_sequences(test_sequences, maxlen=max_length, padding='post')\n",
        "    pred = loaded_model.predict(test_review_pad)\n",
        "    pred*=100\n",
        "    if pred[0][0]>=50: return \"It's a sarcasm!\"\n",
        "    else: return \"It's not a sarcasm.\"\n",
        "\n",
        "# Make predictions using the loaded model\n",
        "prediction = predict_sarcasm(\"I just won million dollars\")\n",
        "print(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5W-ArrrGYsQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "67444219-1591-4265-a275-8a694105d94d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 36ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"It's not a sarcasm.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "predict_sarcasm(\"I want million dollars.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VpxfyH_6GbNg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f68bf21-ef5f-4f88-9f2a-7bfb0dbe4e13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected emojis: ['üòä', '‚ù§']\n"
          ]
        }
      ],
      "source": [
        "import emoji\n",
        "\n",
        "# Define emoji mappings\n",
        "positive_emojis = [\"üòÄ\", \"üòÉ\", \"üòÑ\", \"üòÅ\", \"üòÜ\", \"üòÖ\", \"üòÇ\", \"ü§£\", \"üòä\", \"üòá\", \"üôÇ\", \"üòâ\", \"üòå\", \"üòç\", \"ü•∞\", \"üòò\", \"üòó\", \"üòô\", \"üòö\", \"üòã\", \"üòõ\", \"üòù\", \"üòú\", \"ü§™\", \"üòé\", \"ü§©\", \"ü•≥\", \"üòè\", \"üò¨\", \"ü§ó\"]\n",
        "negative_emojis = [\"ü•π\", \"ü•≤\", \"‚ò∫Ô∏è\", \"üòê\", \"üòë\", \"üò∂\", \"üôÉ\", \"üò∂‚Äçüå´\", \"ü§î\", \"ü´£\", \"ü§≠\", \"ü´°\", \"ü´¢\", \"ü´°\", \"ü§´\", \"ü´†\", \"ü§•\", \"üò∂\", \"ü´•\", \"üòê\", \"ü´§\", \"üòë\", \"ü´®\", \"üôÑ\", \"üòØ\", \"üò¶\", \"üòß\", \"üòÆ\", \"üò≤\", \"ü•±\", \"üò¥\", \"ü§§\", \"üò™\", \"üòµ\", \"ü§ê\", \"ü•¥\", \"ü§¢\", \"ü§ß\", \"üò∑\", \"ü§í\", \"ü§ï\", \"ü§ë\", \"ü§†\"]\n",
        "neutral_emojis = [\"üòû\", \"üòî\", \"üòü\", \"üòï\", \"üôÅ\", \"‚òπÔ∏è\", \"üò£\", \"üòñ\", \"üò´\", \"üò©\", \"ü•∫\", \"üò¢\", \"üò≠\", \"üò§\", \"üò†\", \"üò°\", \"ü§¨\", \"ü§Ø\", \"üò≥\", \"ü•µ\", \"ü•∂\", \"üò±\", \"üò®\", \"üò∞\", \"üò•\", \"üòì\", \"üòû\", \"üòß\", \"üò¶\", \"üòà\", \"üëø\", \"üëπ\", \"üë∫\", \"üí©\", \"üòµ\", \"üòø\"]\n",
        "\n",
        "# Function to detect emojis in text\n",
        "def detect_emojis(text):\n",
        "  emojis = []\n",
        "  for character in text:\n",
        "    if character in emoji.EMOJI_DATA:\n",
        "      emojis.append(character)\n",
        "  return emojis\n",
        "\n",
        "# Example usage\n",
        "text = \"I love Colgate but I don't like its taste üòä‚ù§Ô∏è\"\n",
        "detected_emojis = detect_emojis(text)\n",
        "print(\"Detected emojis:\", detected_emojis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WuTMdSp7HcHn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e81c982a-0897-499e-d962-25859147d93e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 26ms/step\n",
            "Sarcasm Prediction: It's not a sarcasm.\n",
            "Emoji Sentiment: Neutral\n"
          ]
        }
      ],
      "source": [
        "def predict_sarcasm_with_emojis(text):\n",
        "    # Detect emojis in the input text\n",
        "    detected_emojis = detect_emojis(text)\n",
        "\n",
        "    # Predict sarcasm\n",
        "    sarcasm_prediction = predict_sarcasm(text)\n",
        "\n",
        "    # Classify detected emojis as positive, negative, or neutral\n",
        "    emoji_sentiment = classify_emojis(detected_emojis)\n",
        "\n",
        "    # Return sarcasm prediction and emoji sentiment\n",
        "    return sarcasm_prediction, emoji_sentiment\n",
        "\n",
        "def detect_emojis(text):\n",
        "    # Initialize an empty list to store detected emojis\n",
        "    detected_emojis = []\n",
        "\n",
        "    # Iterate through each character in the input text\n",
        "    for character in text:\n",
        "        # Check if the character is an emoji\n",
        "        if emoji.is_emoji(character):\n",
        "            # If it's an emoji, append it to the list of detected emojis\n",
        "            detected_emojis.append(character)\n",
        "\n",
        "    # Return the list of detected emojis\n",
        "    return detected_emojis\n",
        "\n",
        "def classify_emojis(emojis):\n",
        "    # Initialize counts for positive, negative, and neutral emojis\n",
        "    positive_count = 0\n",
        "    negative_count = 0\n",
        "    neutral_count = 0\n",
        "\n",
        "    # Define lists of positive, negative, and neutral emojis\n",
        "    positive_emojis = [\"üòÄ\", \"üòÉ\", \"üòÑ\", \"üòÅ\", \"üòÜ\", \"üòÖ\", \"üòÇ\", \"ü§£\", \"üòä\", \"üòá\", \"üôÇ\", \"üòâ\", \"üòå\", \"üòç\", \"ü•∞\", \"üòò\", \"üòó\", \"üòô\", \"üòö\", \"üòã\", \"üòõ\", \"üòù\", \"üòú\", \"ü§™\", \"üòé\", \"ü§©\", \"ü•≥\", \"üòè\", \"üò¨\", \"ü§ó\"]\n",
        "    negative_emojis = [\"ü•π\", \"ü•≤\", \"‚ò∫Ô∏è\", \"üòê\", \"üòë\", \"üò∂\", \"üôÉ\", \"üò∂‚Äçüå´\", \"ü§î\", \"ü´£\", \"ü§≠\", \"ü´°\", \"ü´¢\", \"ü´°\", \"ü§´\", \"ü´†\", \"ü§•\", \"üò∂\", \"ü´•\", \"üòê\", \"ü´§\", \"üòë\", \"ü´®\", \"üôÑ\", \"üòØ\", \"üò¶\", \"üòß\", \"üòÆ\", \"üò≤\", \"ü•±\", \"üò¥\", \"ü§§\", \"üò™\", \"üòµ\", \"ü§ê\", \"ü•¥\", \"ü§¢\", \"ü§ß\", \"üò∑\", \"ü§í\", \"ü§ï\", \"ü§ë\", \"ü§†\"]\n",
        "    neutral_emojis = [\"üòû\", \"üòî\", \"üòü\", \"üòï\", \"üôÅ\", \"‚òπÔ∏è\", \"üò£\", \"üòñ\", \"üò´\", \"üò©\", \"ü•∫\", \"üò¢\", \"üò≠\", \"üò§\", \"üò†\", \"üò°\", \"ü§¨\", \"ü§Ø\", \"üò≥\", \"ü•µ\", \"ü•∂\", \"üò±\", \"üò®\", \"üò∞\", \"üò•\", \"üòì\", \"üòû\", \"üòß\", \"üò¶\", \"üòà\", \"üëø\", \"üëπ\", \"üë∫\", \"üí©\", \"üòµ\", \"üòø\"]\n",
        "\n",
        "    # Iterate through each emoji in the input list\n",
        "    for emoji in emojis:\n",
        "        # Check if the emoji is positive\n",
        "        if emoji in positive_emojis:\n",
        "            positive_count += 1\n",
        "        # Check if the emoji is negative\n",
        "        elif emoji in negative_emojis:\n",
        "            negative_count += 1\n",
        "        # If it's not positive or negative, consider it neutral\n",
        "        else:\n",
        "            neutral_count += 1\n",
        "\n",
        "    # Determine the overall sentiment based on the majority of emojis\n",
        "    if positive_count > negative_count and positive_count > neutral_count:\n",
        "        return \"Positive\"\n",
        "    elif negative_count > positive_count and negative_count > neutral_count:\n",
        "        return \"Negative\"\n",
        "    else:\n",
        "        return \"Neutral\"\n",
        "\n",
        "# Example usage\n",
        "text = \"I love Colgate but I don't like its taste üôÅ\"\n",
        "sarcasm_prediction, emoji_sentiment = predict_sarcasm_with_emojis(text)\n",
        "print(\"Sarcasm Prediction:\", sarcasm_prediction)\n",
        "print(\"Emoji Sentiment:\", emoji_sentiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qSIA-ZDvOw57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86f12aa6-65f4-46ae-96b8-3c649a065c57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 25ms/step\n",
            "Sarcasm Prediction: It's a sarcasm!\n",
            "Emoji Sentiment: Neutral\n"
          ]
        }
      ],
      "source": [
        "text = \"I just won million dollars üòÜüò∂\"\n",
        "sarcasm_prediction, emoji_sentiment = predict_sarcasm_with_emojis(text)\n",
        "print(\"Sarcasm Prediction:\", sarcasm_prediction)\n",
        "print(\"Emoji Sentiment:\", emoji_sentiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MqSOH6CCZhD2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46db5846-4e4a-411e-f503-5cc247c5b383"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current working directory: /content\n",
            "Directory exists: True\n",
            "Directory: /kaggle/input\n",
            "Files: []\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Print the current working directory\n",
        "print(\"Current working directory:\", os.getcwd())\n",
        "\n",
        "# Check if the directory '/kaggle/input' exists\n",
        "print(\"Directory exists:\", os.path.exists('/kaggle/input'))\n",
        "\n",
        "# Print files and directories in '/kaggle/input'\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    print(\"Directory:\", dirname)\n",
        "    print(\"Files:\", filenames)\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TYpum_FAj0Fn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b2f8ed3-6241-4eb4-820e-34d6a87ca7c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Worksheet retrieved successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "import gspread\n",
        "from google.auth import default\n",
        "creds, _ = default()\n",
        "\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "wb = gc.open_by_key(\"1XJ1f1yLEeh0igyXiim6UEiPjTPDeNja59TweDBLAVjA\")\n",
        "\n",
        "# Get the first worksheet (index 0)\n",
        "ws = wb.get_worksheet(0)\n",
        "\n",
        "# Check if the worksheet was successfully retrieved\n",
        "if ws:\n",
        "    print(\"Worksheet retrieved successfully.\")\n",
        "    # get_all_values gives a list of rows.\n",
        "    rows = ws.get_all_values()\n",
        "    print(rows)\n",
        "else:\n",
        "    print(\"Worksheet not found.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KAFk-3fryp1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e18bb7c1-7d74-45bb-eb6c-1cdec0087139"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                            0   \\\n",
            "0                                      postUrl   \n",
            "1     https://www.instagram.com/p/CotbxWksI1k/   \n",
            "2     https://www.instagram.com/p/CaU0zQ9lk4Q/   \n",
            "3     https://www.instagram.com/p/CosKMGtuzza/   \n",
            "4     https://www.instagram.com/p/CnnDbSnuwJU/   \n",
            "...                                        ...   \n",
            "5213  https://www.instagram.com/p/CJaUauDKN_g/   \n",
            "5214  https://www.instagram.com/p/CJWkp-ipIAB/   \n",
            "5215  https://www.instagram.com/p/CJVakchFy7y/   \n",
            "5216  https://www.instagram.com/p/CJQveYrpYKB/   \n",
            "5217  https://www.instagram.com/p/CJQu_-vJzJq/   \n",
            "\n",
            "                                                1                   2   \\\n",
            "0                                       profileUrl            username   \n",
            "1        https://www.instagram.com/indigirlreviews     indigirlreviews   \n",
            "2         https://www.instagram.com/tiffanyguanuna      tiffanyguanuna   \n",
            "3        https://www.instagram.com/sherellroweshow     sherellroweshow   \n",
            "4               https://www.instagram.com/fit.jaye            fit.jaye   \n",
            "...                                            ...                 ...   \n",
            "5213  https://www.instagram.com/bk_mart_wholesaler  bk_mart_wholesaler   \n",
            "5214     https://www.instagram.com/oyoceryofficial     oyoceryofficial   \n",
            "5215         https://www.instagram.com/samir5haikh         samir5haikh   \n",
            "5216     https://www.instagram.com/oyoceryofficial     oyoceryofficial   \n",
            "5217     https://www.instagram.com/oyoceryofficial     oyoceryofficial   \n",
            "\n",
            "                            3             4          5   \\\n",
            "0                     fullName  commentCount  likeCount   \n",
            "1          ‚ú®Payal‚Äôs Beauty IG‚ú®             2         13   \n",
            "2     Tiffany | NYC Influencer           102        531   \n",
            "3                 ùíÆùíΩùëíùìáùëíùìÅùìÅ ùëÖùëúùìåùëí             9         50   \n",
            "4                     Fit Jaye           194          3   \n",
            "...                        ...           ...        ...   \n",
            "5213        Bk_Mart_Wholesaler             0         13   \n",
            "5214                   oyocery             0          1   \n",
            "5215              SAMIR SHAIKH             0         18   \n",
            "5216                   oyocery             0          1   \n",
            "5217                   oyocery             0          3   \n",
            "\n",
            "                            6   \\\n",
            "0                      pubDate   \n",
            "1     2023-02-16T04:29:44.000Z   \n",
            "2     2022-02-23T15:47:55.000Z   \n",
            "3     2023-02-15T16:36:51.000Z   \n",
            "4     2023-01-19T20:30:00.000Z   \n",
            "...                        ...   \n",
            "5213  2020-12-30T06:06:41.000Z   \n",
            "5214  2020-12-28T19:11:37.000Z   \n",
            "5215  2020-12-28T08:24:14.000Z   \n",
            "5216  2020-12-26T12:50:42.000Z   \n",
            "5217  2020-12-26T12:46:33.000Z   \n",
            "\n",
            "                                                     7   \\\n",
            "0                                           description   \n",
            "1     Thank you @colgate and @hometesterclubna for s...   \n",
            "2     Loving myself on a whole other level these day...   \n",
            "3     SMILE üòÅ \\n\\n#superbowlsunday #sundayfunday #co...   \n",
            "4     Nothing beats a great smile \\n.\\n.\\n.\\n.\\n.\\n....   \n",
            "...                                                 ...   \n",
            "5213  Colgate-Palmolive products are trusted. \\nBy m...   \n",
            "5214  The beautiful alpanas, the beats of dhak and t...   \n",
            "5215      One innocentüòá faceüôÇ!\\n#smilekaroaurshuruhojao   \n",
            "5216  We can‚Äôt wait to hear what you think of our ne...   \n",
            "5217  Is your toothbrush driving germs to your mouth...   \n",
            "\n",
            "                                                     8                    9   \\\n",
            "0                                                imgUrl               postId   \n",
            "1     https://instagram.fhio3-1.fna.fbcdn.net/v/t51....  3039207462292983140   \n",
            "2     https://instagram.fhio3-1.fna.fbcdn.net/v/t51....  2780079091319459344   \n",
            "3     https://instagram.fhio3-1.fna.fbcdn.net/v/t51....  3038848660876770522   \n",
            "4     https://instagram.fhio3-1.fna.fbcdn.net/v/t51....  3019397144734532180   \n",
            "...                                                 ...                  ...   \n",
            "5213  https://instagram.fhio3-1.fna.fbcdn.net/v/t51....  2475380742275260384   \n",
            "5214  https://instagram.fhio3-1.fna.fbcdn.net/v/t51....  2474326259612811265   \n",
            "5215  https://instagram.fhio3-1.fna.fbcdn.net/v/t51....  2474000424040345330   \n",
            "5216  https://instagram.fhio3-1.fna.fbcdn.net/v/t51....  2472684991698797185   \n",
            "5217  https://instagram.fhio3-1.fna.fbcdn.net/v/t51....  2472682902256038506   \n",
            "\n",
            "               10        11                       12  \\\n",
            "0         ownerId      type                    query   \n",
            "1     54767492393     Photo            #colgatesmile   \n",
            "2        24128445  Carousel            #colgatesmile   \n",
            "3        33388254     Photo            #colgatesmile   \n",
            "4     29579937550     Photo            #colgatesmile   \n",
            "...           ...       ...                      ...   \n",
            "5213  40164924891     Photo  #smilekaroaurshuruhojao   \n",
            "5214  14213707947     Photo  #smilekaroaurshuruhojao   \n",
            "5215  17081319233     Photo  #smilekaroaurshuruhojao   \n",
            "5216  14213707947     Photo  #smilekaroaurshuruhojao   \n",
            "5217  14213707947     Photo  #smilekaroaurshuruhojao   \n",
            "\n",
            "                            13                   14         15             16  \\\n",
            "0                    timestamp             location  isSidecar  sidecarMedias   \n",
            "1     2023-02-16T05:37:15.109Z                           FALSE                  \n",
            "2     2023-02-16T05:37:15.109Z  New York City, N.Y.       TRUE              4   \n",
            "3     2023-02-16T05:37:15.109Z                           FALSE                  \n",
            "4     2023-02-16T05:37:15.109Z                           FALSE                  \n",
            "...                        ...                  ...        ...            ...   \n",
            "5213  2023-02-16T05:57:26.954Z                           FALSE                  \n",
            "5214  2023-02-16T05:57:26.954Z                           FALSE                  \n",
            "5215  2023-02-16T05:57:26.954Z                           FALSE                  \n",
            "5216  2023-02-16T05:57:26.954Z                           FALSE                  \n",
            "5217  2023-02-16T05:57:26.954Z                           FALSE                  \n",
            "\n",
            "             17        18  \n",
            "0     viewCount  videoUrl  \n",
            "1                          \n",
            "2                          \n",
            "3                          \n",
            "4                          \n",
            "...         ...       ...  \n",
            "5213                       \n",
            "5214                       \n",
            "5215                       \n",
            "5216                       \n",
            "5217                       \n",
            "\n",
            "[5218 rows x 19 columns]\n"
          ]
        }
      ],
      "source": [
        "df1 = pd.DataFrame(rows)\n",
        "\n",
        "# Print the DataFrame to inspect its structure\n",
        "print(df1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pHAuzNOiy_7R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "1ab7eb7b-d728-4a44-c3b7-206fcabbe994"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/Colgate Scrapped Dataset - Post_data_Final.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-3540ce6fa62c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/Colgate Scrapped Dataset - Post_data_Final.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/Colgate Scrapped Dataset - Post_data_Final.csv'"
          ]
        }
      ],
      "source": [
        "cs = pd.read_csv(\"/content/Colgate Scrapped Dataset - Post_data_Final.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZPwF3tPT1K__"
      },
      "outputs": [],
      "source": [
        "cs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "13j7X9X71SF-"
      },
      "outputs": [],
      "source": [
        "rows = cs.values.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XOmblJIn4B63"
      },
      "outputs": [],
      "source": [
        "#defining positive, negative and connectors lists of words\n",
        "\n",
        "positive = [\"love\",\"like\",\"happy\",\"good\",\"excellent\",\"great\",\"nice\",\"wonderful\",\"fantastic\",\"amazing\",\"awesome\",\"terrific\",\"fabulous\",\"delightful\",\"pleasure\",\"enjoy\",\n",
        "    \"satisfy\",\"smile\",\"laugh\",\"success\",\"kind\",\"generous\",\"gracious\",\"forgiving\",\"compassionate\",\"understanding\",\"trust\",\"loyal\",\"honest\",\"fair\",\"brave\",\n",
        "    \"adventurous\",\"confident\",\"creative\",\"smart\",\"intelligent\",\"insightful\",\"inspiring\",\"motivated\",\"passionate\",\"productive\",\"focused\",\"disciplined\",\"healthy\",\n",
        "    \"energetic\",\"athletic\",\"beautiful\",\"attractive\",\"fashionable\",\"stylish\",\"successful\",\"wealthy\",\"rich\",\"prosperous\",\"abundant\",\"blessed\",\"fortunate\",\"lucky\",\n",
        "    \"grateful\",\"content\",\"peaceful\",\"calm\",\"relaxed\",\"tranquil\",\"serene\",\"happy\",\"joyful\",\"blissful\",\"ecstatic\",\"hopeful\",\"optimistic\",\"courageous\",\"confident\",\n",
        "    \"proud\",\"admire\",\"respect\",\"appreciate\",\"significant\",\"glad\",\"perfect\",\"rapturous\", \"fascinating\", \"enriching\", \"tranquilizing\", \"blissful\", \"serendipitous\", \"inspirational\", \"pleasurable\", \"upbeat\", \"ecstatic\",\n",
        "    \"delicious\", \"exhilarating\", \"glamorous\",\"Colgate\" ,\"majestic\", \"stunning\", \"irresistible\", \"breathtaking\", \"prodigious\", \"miraculous\", \"miracle\",\"thrilling\",\n",
        "    \"mind-blowing\", \"exquisite\", \"alluring\", \"extraordinary\", \"spectacular\", \"outstanding\", \"remarkable\", \"unforgettable\", \"marvelous\", \"unbeatable\", \"brilliant\", \"genius\", \"stellar\", \"fantabulous\", \"incredible\", \"sublime\",\n",
        "    \"superb\", \"terrific\", \"top-notch\", \"wondrous\",\"Colgate\"]\n",
        "\n",
        "negative = [\"not\",\"neither\",\"don't\",\"didn't\",\"wouldn't\",\"shouldn't\",\"haven't\",\"hadn't\",\"can't\",\"hate\",\"unhappy\",\"bad\",\"terrible\",\"uncomfortable\",\"horrible\",\"awful\",\"disgusting\",\"ugly\",\"painful\",\n",
        "    \"sorrow\",\"hurt\",\"upset\",\"frustrated\",\"angry\",\"annoyed\",\"disappointed\",\"regret\",\"guilt\",\"shame\",\"fear\",\"scared\",\"anxious\",\"worried\",\"nervous\",\"doubt\",\"insecure\",\n",
        "    \"jealous\",\"envy\",\"betray\",\"abandon\",\"alone\",\"lonely\",\"depressed\",\"sad\",\"miserable\",\"gloomy\",\"hopeless\",\"despair\",\"powerless\",\"worthless\",\"rejected\",\"humiliated\",\n",
        "    \"insulted\",\"offended\",\"disrespected\",\"unappreciated\",\"frustrated\",\"overwhelmed\",\"exhausted\",\"tired\",\"bored\",\"stressed\",\"irritated\",\"annoying\",\"negative\",\"critical\",\n",
        "    \"mean\",\"cruel\",\"selfish\",\"arrogant\",\"ignorant\",\"stupid\",\"lazy\",\"unmotivated\",\"unproductive\",\"unsuccessful\",\"poor\",\"struggle\",\"failure\",\"loss\",\"difficult\",\"tragic\",\n",
        "    \"disastrous\",\"devastating\",\"pathetic\",\"disappointing\",\"regretful\",\"heartbroken\",\"wounded\",\"insensitive\",\"impolite\",\"unfriendly\",\"cynical\",\"pessimistic\",\"cowardly\",\n",
        "    \"indecisive\",\"irresponsible\",\"foolish\",\"weak\",\"worthless\",\"incompetent\",\"dependent\",\"unreliable\",\"untrustworthy\",\"unhealthy\",\"unfit\",\"unattractive\",\"poor\",\"broke\",\n",
        "    \"struggling\",\"difficult\",\"disgusted\",\"offended\",\"trapped\",\"stuck\",\"lonely\",\"empty\",\"lost\",\"confused\",\"ashamed\",\"humiliated\",\"horrified\",\"disillusioned\",\"depressed\",\n",
        "    \"unhappy\",\"bitter\",\"enraged\",\"resentful\",\"discontented\",\"displeased\",\"worried\",\"nervous\",\"fearful\",\"anxious\",\"terrified\",\"petrified\",\"timid\",\"shy\",\"insecure\",\n",
        "    \"uncertain\",\"doubtful\",\"skeptical\",\"disbelieving\",\"inattentive\",\"distracted\",\"absent-minded\",\"forgetful\",\"neglectful\",\"careless\",\"reckless\",\"irresponsible\",\n",
        "    \"impulsive\",\"careless\",\"inconsiderate\",\"thoughtless\",\"selfish\",\"self-centered\",\"egotistical\",\"arrogant\",\"ignorant\",\"inflexible\",\"stubborn\",\"rigid\",\"boring\",\"weird\"\n",
        "    \"monotonous\",\"repetitive\",\"tedious\",\"dull\",\"uninteresting\",\"unexciting\",\"mundane\",\"trivial\",\"unimportant\",\"insignificant\",\"meaningless\",\"worthless\",\"disappointed\"]\n",
        "\n",
        "#connectors are the subordinating conjunctions which join two or more phrases + punctuations\n",
        "connectors = [\"for\",\"and\",\"nor\",\"but\",\"or\",\"yet\",\"so\",\",\",\";\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fDrmDzVL6l4u"
      },
      "outputs": [],
      "source": [
        "def encodeSentence(sentence):\n",
        "  # words = sentence.split()\n",
        "  words = re.findall(r\"[\\w']+|[^\\w\\s]\", sentence)\n",
        "  encoded_sentence = []\n",
        "  for word in words:\n",
        "    if any(char.isdigit() or char.isalpha() for char in word):\n",
        "      if word in positive:\n",
        "        encoded_sentence.append(2)\n",
        "\n",
        "      elif word in negative:\n",
        "        encoded_sentence.append(0)\n",
        "\n",
        "      elif word in connectors:\n",
        "        encoded_sentence.append(3)\n",
        "\n",
        "      else:\n",
        "        encoded_sentence.append(1)\n",
        "\n",
        "    else:\n",
        "      encoded_sentence.append(3)\n",
        "\n",
        "  return encoded_sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kDEvdwXl6z6q"
      },
      "outputs": [],
      "source": [
        "def createTree(encoded_sentence):\n",
        "  tree_diagram =[]\n",
        "  N = len(encoded_sentence)\n",
        "  count = 0\n",
        "\n",
        "  for i in range(0,N+1):\n",
        "    tree_diagram.append([])\n",
        "\n",
        "  for code in encoded_sentence:\n",
        "    if count == N:\n",
        "      tree_diagram[count-1].append(code)\n",
        "    elif count == 0:\n",
        "      tree_diagram[count].append(code)\n",
        "      tree_diagram[count].append(None)\n",
        "    else:\n",
        "      tree_diagram[count].append(code)\n",
        "      tree_diagram[count].append(None)\n",
        "\n",
        "    count = count+1\n",
        "\n",
        "  return tree_diagram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "paXUGsfs61yu"
      },
      "outputs": [],
      "source": [
        "def calculateValue(temp,tree):\n",
        "  result = 1\n",
        "\n",
        "  if tree[temp][0]==0 and tree[temp][1]==1:\n",
        "        result=0\n",
        "  elif tree[temp][0] == 0 and tree[temp][1] == 0:\n",
        "        result = 2\n",
        "  elif tree[temp][0] == 1 and tree[temp][1] == 1:\n",
        "        result = 1\n",
        "  elif tree[temp][0] == 1 and tree[temp][1] == 0:\n",
        "        result = 0\n",
        "  elif tree[temp][0] == 1 and tree[temp][1] == 2:\n",
        "        result = 2\n",
        "  elif tree[temp][0] == 2 and tree[temp][1] == 2:\n",
        "        result = 2\n",
        "  elif tree[temp][0] == 2 and tree[temp][1] == 1:\n",
        "      result = 2\n",
        "  elif tree[temp][0] == 0 and tree[temp][1] == 2:\n",
        "        result = 0\n",
        "  elif tree[temp][0] == 2 and tree[temp][1] == 0:\n",
        "        result = 0\n",
        "\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-KIiJbZD64Mn"
      },
      "outputs": [],
      "source": [
        "def calculateSentiment(temp):\n",
        "  result = 1\n",
        "\n",
        "  if sentiment_tree[temp][0]==0 and sentiment_tree[temp][1]==1:\n",
        "        result=0\n",
        "  elif sentiment_tree[temp][0] == 0 and sentiment_tree[temp][1] == 0:\n",
        "        result = 0\n",
        "  elif sentiment_tree[temp][0] == 1 and sentiment_tree[temp][1] == 1:\n",
        "        result = 1\n",
        "  elif sentiment_tree[temp][0] == 1 and sentiment_tree[temp][1] == 0:\n",
        "        result = 0\n",
        "  elif sentiment_tree[temp][0] == 1 and sentiment_tree[temp][1] == 2:\n",
        "        result = 2\n",
        "  elif sentiment_tree[temp][0] == 2 and sentiment_tree[temp][1] == 2:\n",
        "        result = 2\n",
        "  elif sentiment_tree[temp][0] == 2 and sentiment_tree[temp][1] == 1:\n",
        "      result = 2\n",
        "  elif sentiment_tree[temp][0] == 0 and sentiment_tree[temp][1] == 2:\n",
        "        result = 2\n",
        "  elif sentiment_tree[temp][0] == 2 and sentiment_tree[temp][1] == 0:\n",
        "        result = 0\n",
        "\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XgLsDLQs6_Bm"
      },
      "outputs": [],
      "source": [
        "#Live Prediction\n",
        "def prediction(s):\n",
        "    x_final = pd.DataFrame({\"headline\":[s]})\n",
        "    test_lines = CleanTokenize(x_final)\n",
        "    test_sequences = tokenizer_obj.texts_to_sequences(test_lines)\n",
        "    test_review_pad = pad_sequences(test_sequences, maxlen=max_length, padding='post')\n",
        "    pred = loaded_model.predict(test_review_pad)\n",
        "    pred*=100\n",
        "    if pred[0][0]>=50: return \"It's a sarcasm!\"\n",
        "    else: return \"It's not a sarcasm.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ogPVxvW7Dx6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "de76be2b-12b5-4082-b666-178b3ea8e791"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 25ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"It's a sarcasm!\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "prediction(\"I was depressed. He asked me to be happy. I am not depressed anymore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fdyIZZEa7IuT"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "result_list = ['Negative', 'Neutral', 'Positive']\n",
        "final = []\n",
        "\n",
        "testSentences = [\"I love Colgate but I don't like its taste\"]\n",
        "\n",
        "for sentence in testSentences:\n",
        "  # sentence = row['description']\n",
        "  tree = createTree(encodeSentence(sentence))\n",
        "  sentiment = []\n",
        "  result = []\n",
        "  encoded_sentence = encodeSentence(sentence)\n",
        "  # print(sentence, encoded_sentence)\n",
        "  list_splits = []\n",
        "  start_index = 0\n",
        "  #splitting the sentences by connectors\n",
        "  for i, value in enumerate(encoded_sentence):\n",
        "      if value == 3:\n",
        "          list_splits.append(encoded_sentence[start_index:i])\n",
        "          start_index = i + 1\n",
        "  list_splits.append(encoded_sentence[start_index:])\n",
        "  # print(encoded_sentence, list_splits)\n",
        "  # Create a tree for each split\n",
        "  for split in list_splits:\n",
        "    if split:\n",
        "      tree = createTree(split)\n",
        "      # print(split, tree)\n",
        "      #getting sentiment of splits\n",
        "      N = len(split)\n",
        "      temp = N\n",
        "      # print(N)\n",
        "      for i in range(0, N):\n",
        "        temp = temp -1\n",
        "        if i == 0:\n",
        "          tree[temp][1]=1\n",
        "        else:\n",
        "          tree[temp][1] = calculateValue(temp+1,tree)\n",
        "    sentiment.append(calculateValue(temp,tree))\n",
        "    # print(tree, sentiment)\n",
        "\n",
        "#       # print(\"Encoded Sentence:\", encoded_sentence)\n",
        "#       # print(\"Split Lists:\", list_splits)\n",
        "#       # print(\"Sentiment:\", sentiment)\n",
        "\n",
        "  #creating tree for sentiments\n",
        "  sentiment_tree = createTree(sentiment)\n",
        "  # print(sentiment, sentiment_tree)\n",
        "  # print(len(sentiment_tree))\n",
        "  N = len(sentiment)\n",
        "  # print(N)\n",
        "  temp = N\n",
        "\n",
        "  for i in range(0,N):\n",
        "    # print(sentiment_tree)\n",
        "    temp=temp-1\n",
        "    # print(temp, i)\n",
        "    if i == 0:\n",
        "      sentiment_tree[temp][1]=1\n",
        "    else:\n",
        "      sentiment_tree[temp][1] = calculateSentiment(temp+1)\n",
        "  # print(sentiment, sentiment_tree)\n",
        "\n",
        "  final.append(calculateSentiment(temp))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lXrl6nJt7KuZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16690479-706c-40cc-ae2c-7dacd53a6a7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I love Colgate but I don't like its taste - Negative\n"
          ]
        }
      ],
      "source": [
        "for i in final:\n",
        "  if i == 0:\n",
        "    print(f'{testSentences[0]} - Negative')\n",
        "  if i == 1:\n",
        "    print(f'{testSentences[0]} - Neutral')\n",
        "  if i == 2:\n",
        "    print(f'{testSentences[0]} - Positive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AmAAN5G57NPj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0edf20de-19d3-483f-d7e6-b1891e515376"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 24ms/step\n",
            "It's not a sarcasm.\n",
            "Neutral\n"
          ]
        }
      ],
      "source": [
        "text = \"I love Colgate but I don't like its taste üôÅ\"\n",
        "sarcasm_prediction, emoji_sentiment = predict_sarcasm_with_emojis(text)\n",
        "print(sarcasm_prediction)\n",
        "print(emoji_sentiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DY8WRWPl71C9"
      },
      "outputs": [],
      "source": [
        "def perform_sentiment_analysis(text):\n",
        "    # Convert text to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove punctuation marks\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "\n",
        "    # Tokenize the text into words\n",
        "    words = text.split()\n",
        "\n",
        "    # Initialize sentiment score\n",
        "    score = 0\n",
        "\n",
        "    # Iterate through each word in the text\n",
        "    for word in words:\n",
        "        # Check if the word is in the positive list\n",
        "        if word in positive:\n",
        "            score += 1\n",
        "        # Check if the word is in the negative list\n",
        "        elif word in negative:\n",
        "            score -= 1\n",
        "\n",
        "    # Classify sentiment based on the score\n",
        "    if score > 0:\n",
        "        return \"Positive\"\n",
        "    elif score < 0:\n",
        "        return \"Negative\"\n",
        "    else:\n",
        "        return \"Neutral\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g9i0x0jH-CaZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57ba848a-c406-407d-e413-92bcc476dcd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 25ms/step\n",
            "Sarcasm Prediction: It's not a sarcasm.\n",
            "Emoji Sentiment: Neutral\n",
            "Sentiment Analysis: Positive\n"
          ]
        }
      ],
      "source": [
        "text = \"I love Colgate but I don't like its taste üôÅ\"\n",
        "sarcasm_prediction, emoji_sentiment = predict_sarcasm_with_emojis(text)\n",
        "sentiment = perform_sentiment_analysis(text)\n",
        "\n",
        "print(\"Sarcasm Prediction:\", sarcasm_prediction)\n",
        "print(\"Emoji Sentiment:\", emoji_sentiment)\n",
        "print(\"Sentiment Analysis:\", sentiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DqSWmbh0-EzX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4be7a03e-208f-4125-cc91-0c633ee08455"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 23ms/step\n",
            "Final Sentiment: Negative\n",
            "Sarcasm Prediction: Not a Sarcasm.\n",
            "Emoji Sentiment: Neutral\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "def predict_sentiment_with_emoji_and_sarcasm(text):\n",
        "    # Sentiment Tree Prediction\n",
        "    def encodeSentence(sentence):\n",
        "        # words = sentence.split()\n",
        "        words = re.findall(r\"[\\w']+|[^\\w\\s]\", sentence)\n",
        "        encoded_sentence = []\n",
        "        for word in words:\n",
        "            if any(char.isdigit() or char.isalpha() for char in word):\n",
        "                if word in positive:\n",
        "                    encoded_sentence.append(2)\n",
        "                elif word in negative:\n",
        "                    encoded_sentence.append(0)\n",
        "                elif word in connectors:\n",
        "                    encoded_sentence.append(3)\n",
        "                else:\n",
        "                    encoded_sentence.append(1)\n",
        "            else:\n",
        "                encoded_sentence.append(3)\n",
        "        return encoded_sentence\n",
        "\n",
        "    def createTree(encoded_sentence):\n",
        "        tree_diagram = []\n",
        "        N = len(encoded_sentence)\n",
        "        count = 0\n",
        "\n",
        "        for i in range(0, N + 1):\n",
        "            tree_diagram.append([])\n",
        "\n",
        "        for code in encoded_sentence:\n",
        "            if count == N:\n",
        "                tree_diagram[count - 1].append(code)\n",
        "            elif count == 0:\n",
        "                tree_diagram[count].append(code)\n",
        "                tree_diagram[count].append(None)\n",
        "            else:\n",
        "                tree_diagram[count].append(code)\n",
        "                tree_diagram[count].append(None)\n",
        "\n",
        "            count = count + 1\n",
        "\n",
        "        return tree_diagram\n",
        "\n",
        "    def calculateValue(temp, tree):\n",
        "        result = 1\n",
        "        if tree[temp][0] == 0 and tree[temp][1] == 1:\n",
        "            result = 0\n",
        "        elif tree[temp][0] == 0 and tree[temp][1] == 0:\n",
        "            result = 2\n",
        "        elif tree[temp][0] == 1 and tree[temp][1] == 1:\n",
        "            result = 1\n",
        "        elif tree[temp][0] == 1 and tree[temp][1] == 0:\n",
        "            result = 0\n",
        "        elif tree[temp][0] == 1 and tree[temp][1] == 2:\n",
        "            result = 2\n",
        "        elif tree[temp][0] == 2 and tree[temp][1] == 2:\n",
        "            result = 2\n",
        "        elif tree[temp][0] == 2 and tree[temp][1] == 1:\n",
        "            result = 2\n",
        "        elif tree[temp][0] == 0 and tree[temp][1] == 2:\n",
        "            result = 0\n",
        "        elif tree[temp][0] == 2 and tree[temp][1] == 0:\n",
        "            result = 0\n",
        "        return result\n",
        "\n",
        "    def calculateSentiment(temp, sentiment_tree):\n",
        "        result = 1\n",
        "        if sentiment_tree[temp][0] == 0 and sentiment_tree[temp][1] == 1:\n",
        "            result = 0\n",
        "        elif sentiment_tree[temp][0] == 0 and sentiment_tree[temp][1] == 0:\n",
        "            result = 2\n",
        "        elif sentiment_tree[temp][0] == 1 and sentiment_tree[temp][1] == 1:\n",
        "            result = 1\n",
        "        elif sentiment_tree[temp][0] == 1 and sentiment_tree[temp][1] == 0:\n",
        "            result = 0\n",
        "        elif sentiment_tree[temp][0] == 1 and sentiment_tree[temp][1] == 2:\n",
        "            result = 2\n",
        "        elif sentiment_tree[temp][0] == 2 and sentiment_tree[temp][1] == 2:\n",
        "            result = 2\n",
        "        elif sentiment_tree[temp][0] == 2 and sentiment_tree[temp][1] == 1:\n",
        "            result = 2\n",
        "        elif sentiment_tree[temp][0] == 0 and sentiment_tree[temp][1] == 2:\n",
        "            result = 0\n",
        "        elif sentiment_tree[temp][0] == 2 and sentiment_tree[temp][1] == 0:\n",
        "            result = 0\n",
        "        return result\n",
        "\n",
        "    def sarcasm_prediction(text):\n",
        "        x_final = pd.DataFrame({\"headline\":[text]})\n",
        "        test_lines = CleanTokenize(x_final)\n",
        "        test_sequences = tokenizer_obj.texts_to_sequences(test_lines)\n",
        "        test_review_pad = pad_sequences(test_sequences, maxlen=max_length, padding='post')\n",
        "        pred = loaded_model.predict(test_review_pad)\n",
        "        pred *= 100\n",
        "        if pred[0][0] >= 50:\n",
        "            return \"Sarcasm Detected!\"\n",
        "        else:\n",
        "            return \"Not a Sarcasm.\"\n",
        "\n",
        "    def emoji_sentiment(text):\n",
        "        detected_emojis = detect_emojis(text)\n",
        "        emoji_sentiment = classify_emojis(detected_emojis)\n",
        "        return emoji_sentiment\n",
        "\n",
        "    result_list = ['Negative', 'Neutral', 'Positive']\n",
        "    final_sentiment = None\n",
        "\n",
        "    testSentences = [text]\n",
        "\n",
        "    for sentence in testSentences:\n",
        "        tree = createTree(encodeSentence(sentence))\n",
        "        sentiment = []\n",
        "        result = []\n",
        "        encoded_sentence = encodeSentence(sentence)\n",
        "\n",
        "        list_splits = []\n",
        "        start_index = 0\n",
        "\n",
        "        for i, value in enumerate(encoded_sentence):\n",
        "            if value == 3:\n",
        "                list_splits.append(encoded_sentence[start_index:i])\n",
        "                start_index = i + 1\n",
        "        list_splits.append(encoded_sentence[start_index:])\n",
        "\n",
        "        for split in list_splits:\n",
        "            if split:\n",
        "                tree = createTree(split)\n",
        "                N = len(split)\n",
        "                temp = N\n",
        "                for i in range(0, N):\n",
        "                    temp = temp - 1\n",
        "                    if i == 0:\n",
        "                        tree[temp][1] = 1\n",
        "                    else:\n",
        "                        tree[temp][1] = calculateValue(temp + 1, tree)\n",
        "                sentiment.append(calculateValue(temp, tree))\n",
        "\n",
        "        sentiment_tree = createTree(sentiment)\n",
        "        N = len(sentiment)\n",
        "        temp = N\n",
        "\n",
        "        for i in range(0, N):\n",
        "            temp = temp - 1\n",
        "            if i == 0:\n",
        "                sentiment_tree[temp][1] = 1\n",
        "            else:\n",
        "                sentiment_tree[temp][1] = calculateSentiment(temp + 1, sentiment_tree)\n",
        "\n",
        "        final_sentiment = calculateSentiment(temp, sentiment_tree)\n",
        "\n",
        "    sarcasm_result = sarcasm_prediction(text)\n",
        "    emoji_result = emoji_sentiment(text)\n",
        "\n",
        "    return final_sentiment, sarcasm_result, emoji_result\n",
        "\n",
        "# Test the function with a sample text\n",
        "text = \"I love Colgate but I don't like its taste\"\n",
        "final_sentiment, sarcasm_result, emoji_result = predict_sentiment_with_emoji_and_sarcasm(text)\n",
        "print(\"Final Sentiment:\", result_list[final_sentiment])\n",
        "print(\"Sarcasm Prediction:\", sarcasm_result)\n",
        "print(\"Emoji Sentiment:\", emoji_result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYuHq9PbEyqe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b74faa1-4a3e-4229-986f-88860774c483"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 27ms/step\n",
            "Final Sentiment: Negative\n",
            "Sarcasm Prediction: Not a Sarcasm.\n",
            "Emoji Sentiment: Negative\n"
          ]
        }
      ],
      "source": [
        "text = \"I love Colgate but I don't like its taste üòë\"\n",
        "final_sentiment, sarcasm_result, emoji_result = predict_sentiment_with_emoji_and_sarcasm(text)\n",
        "print(\"Final Sentiment:\", result_list[final_sentiment])\n",
        "print(\"Sarcasm Prediction:\", sarcasm_result)\n",
        "print(\"Emoji Sentiment:\", emoji_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Tu6rt4fwkTF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69715bdc-3c08-44ed-e5de-7cb6c669e6fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Punctuation marks found in the sentence:\n",
            "!: exclamation mark (indicates strong feeling or surprise)\n",
            "': apostrophe (indicates possession or omitted letters)\n",
            "?: question mark (indicates a question)\n",
            "Overall meaning of the sentence:\n",
            "The last punctuation mark '?' suggests 'question mark (indicates a question)'.\n"
          ]
        }
      ],
      "source": [
        "def check_punctuation(sentence):\n",
        "    punctuation_marks = ['.', ',', ';', ':', '?', '!', '-', \"'\", '\"', '(', ')', '[', ']', '{', '}', '/', '\\\\', '<', '>', '|', '*', '&', '@', '#', '%', '^', '_', '+', '=', '~', '`', '$', '&', '¬£', '‚Ç¨', '¬•', '¬¢', '¬§', '¬ß', '¬©', '¬Æ', '‚Ñ¢', '¬¨', '¬¶', '¬µ', '¬±', '√ó', '√∑', '¬¢', '‡∏ø', '‚Ç°', '‚Ç¢', '‚Ç£', '‚Ç§', '‚Ç•', '‚Ç¶', '‚Çß', '‚Ç®', '‚Ç©', '‚Ç™', '‚Ç´', '‚Ç¨', '‚Ç≠', '‚ÇÆ', '‚ÇØ', '‚Ç∞', '‚Ç±', '‚Ç≤', '‚Ç≥', '‚Ç¥', '‚Çµ', '‚Ç∂', '‚Ç∑', '‚Ç∏', '‚Çπ', '‚Ç∫', '‚Çª', '‚Çº', '‚ÇΩ', '‚Çæ', '‚Çø']\n",
        "\n",
        "    punctuation_meanings = {\n",
        "        '.': 'period (indicates the end of a sentence)',\n",
        "        ',': 'comma (separates items in a list or series)',\n",
        "        ';': 'semicolon (indicates a pause or separates independent clauses)',\n",
        "        ':': 'colon (introduces a list or explanation)',\n",
        "        '?': 'question mark (indicates a question)',\n",
        "        '!': 'exclamation mark (indicates strong feeling or surprise)',\n",
        "        '-': 'hyphen (joins words or parts of words)',\n",
        "        \"'\": 'apostrophe (indicates possession or omitted letters)',\n",
        "        '\"': 'quotation mark (indicates speech or a quotation)',\n",
        "        '(': 'left parenthesis (encloses additional information)',\n",
        "        ')': 'right parenthesis (encloses additional information)',\n",
        "        '[': 'left square bracket (encloses additional information)',\n",
        "        ']': 'right square bracket (encloses additional information)',\n",
        "        '{': 'left curly bracket (encloses additional information)',\n",
        "        '}': 'right curly bracket (encloses additional information)',\n",
        "        '/': 'forward slash (used in URLs, paths, or fractions)',\n",
        "        '\\\\': 'backslash (used in file paths or escape characters)',\n",
        "        '<': 'less than sign (used in mathematical expressions or HTML tags)',\n",
        "        '>': 'greater than sign (used in mathematical expressions or HTML tags)',\n",
        "        '|': 'vertical bar or pipe (used in programming or to denote alternatives)',\n",
        "        '*': 'asterisk (used for multiplication, wildcard characters, or emphasis)',\n",
        "        '&': 'ampersand (represents \"and\", used in HTML or programming)',\n",
        "        '@': 'at symbol (used in email addresses or social media handles)',\n",
        "        '#': 'hashtag (used in social media to categorize topics)',\n",
        "        '%': 'percent sign (indicates a percentage)',\n",
        "        '^': 'caret (used in mathematical expressions or to denote exponentiation)',\n",
        "        '_': 'underscore (used in programming or for emphasis)',\n",
        "        '+': 'plus sign (used in mathematical expressions or to denote addition)',\n",
        "        '=': 'equal sign (indicates equality or assignment)',\n",
        "        '~': 'tilde (used in programming or as a diacritical mark)',\n",
        "        '`': 'grave accent (used in programming or as a diacritical mark)',\n",
        "        '$': 'dollar sign (used to denote currency)',\n",
        "        '¬£': 'pound sign (used to denote currency)',\n",
        "        '‚Ç¨': 'euro sign (used to denote currency)',\n",
        "        '¬•': 'yen sign (used to denote currency)',\n",
        "        '¬¢': 'cent sign (used to denote currency)',\n",
        "        '¬§': 'currency sign (used to denote currency)',\n",
        "        '¬ß': 'section sign (used in legal documents or to denote a section)',\n",
        "        '¬©': 'copyright symbol (indicates ownership of intellectual property)',\n",
        "        '¬Æ': 'registered trademark symbol (indicates a registered trademark)',\n",
        "        '‚Ñ¢': 'trademark symbol (indicates a trademark)',\n",
        "        '¬¨': 'negation symbol (used in logic or to indicate a negative)',\n",
        "        '¬¶': 'broken vertical bar (used to denote alternatives or separate clauses)',\n",
        "        '¬µ': 'micro sign (used in scientific notation or to denote micro- units)',\n",
        "        '¬±': 'plus-minus sign (indicates a range of values)',\n",
        "        '√ó': 'multiplication sign (indicates multiplication)',\n",
        "        '√∑': 'division sign (indicates division)',\n",
        "        '‡∏ø': 'baht sign (used to denote currency)',\n",
        "        '‚Ç°': 'colon sign (used to denote currency)',\n",
        "        '‚Ç¢': 'cruzeiro sign (used to denote currency)',\n",
        "        '‚Ç£': 'french franc sign (used to denote currency)',\n",
        "        '‚Ç§': 'lira sign (used to denote currency)',\n",
        "        '‚Ç•': 'mill sign (used to denote currency)',\n",
        "        '‚Ç¶': 'naira sign (used to denote currency)',\n",
        "        '‚Çß': 'peseta sign (used to denote currency)',\n",
        "        '‚Ç®': 'rupee sign (used to denote currency)',\n",
        "        '‚Ç©': 'won sign (used to denote currency)',\n",
        "        '‚Ç™': 'new sheqel sign (used to denote currency)',\n",
        "        '‚Ç´': 'dong sign (used to denote currency)',\n",
        "        '‚Ç≠': 'kip sign (used to denote currency)',\n",
        "        '‚ÇÆ': 'tugrik sign (used to denote currency)',\n",
        "        '‚ÇØ': 'drachma sign (used to denote currency)',\n",
        "        '‚Ç∞': 'german penny sign (used to denote currency)',\n",
        "        '‚Ç±': 'peso sign (used to denote currency)',\n",
        "        '‚Ç≤': 'guarani sign (used to denote currency)',\n",
        "        '‚Ç≥': 'austral sign (used to denote currency)',\n",
        "        '‚Ç¥': 'hryvnia sign (used to denote currency)',\n",
        "        '‚Çµ': 'cedi sign (used to denote currency)',\n",
        "        '‚Ç∂': 'livre tournois sign (used to denote currency)',\n",
        "        '‚Ç∑': 'spesmilo sign (used to denote currency)',\n",
        "        '‚Ç∏': 'tenge sign (used to denote currency)',\n",
        "        '‚Çπ': 'indian rupee sign (used to denote currency)',\n",
        "        '‚Ç∫': 'turkish lira sign (used to denote currency)',\n",
        "        '‚Çª': 'nordic mark sign (used to denote currency)',\n",
        "        '‚Çº': 'manat sign (used to denote currency)',\n",
        "        '‚ÇΩ': 'ruble sign (used to denote currency)',\n",
        "        '‚Çæ': 'lari sign (used to denote currency)',\n",
        "        '‚Çø': 'bitcoin sign (used to denote cryptocurrency)'\n",
        "    }\n",
        "\n",
        "\n",
        "    found_punctuation = []\n",
        "\n",
        "    for char in sentence:\n",
        "        if char in punctuation_marks:\n",
        "            found_punctuation.append((char, punctuation_meanings[char]))\n",
        "\n",
        "    if not found_punctuation:\n",
        "        print(\"No punctuation marks found in the sentence.\")\n",
        "    else:\n",
        "        print(\"Punctuation marks found in the sentence:\")\n",
        "        for punctuation, meaning in found_punctuation:\n",
        "            print(f\"{punctuation}: {meaning}\")\n",
        "\n",
        "        print(\"Overall meaning of the sentence:\")\n",
        "        print(f\"The last punctuation mark '{found_punctuation[-1][0]}' suggests '{found_punctuation[-1][1]}'.\")\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "sentence = \"What a beautiful day! Isn't it?\"\n",
        "check_punctuation(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "siQWK3m7Ecx2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c914b86-4f1f-4048-b2ab-25c5ff759438"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 47ms/step\n",
            "Punctuation marks found in the sentence:\n",
            "': apostrophe (indicates possession or omitted letters)\n",
            "!: exclamation mark (indicates strong feeling or surprise)\n",
            "Overall meaning of the sentence:\n",
            "The last punctuation mark '!' suggests 'exclamation mark (indicates strong feeling or surprise)'.\n",
            "punctuation:  None\n",
            "Final Sentiment: Negative\n",
            "Sarcasm Prediction: Not a Sarcasm.\n",
            "Emoji Sentiment: Negative\n"
          ]
        }
      ],
      "source": [
        "text = \"I love Colgate but I don't like its taste üòë!\"\n",
        "final_sentiment, sarcasm_result, emoji_result = predict_sentiment_with_emoji_and_sarcasm(text)\n",
        "print(\"punctuation: \",check_punctuation(text))\n",
        "print(\"Final Sentiment:\", result_list[final_sentiment])\n",
        "print(\"Sarcasm Prediction:\", sarcasm_result)\n",
        "print(\"Emoji Sentiment:\", emoji_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bG0xYat27Qnq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcc4981c-99a4-48fd-f6b5-9dca68d81e3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 36ms/step\n",
            "Punctuation marks found in the sentence:\n",
            "!: exclamation mark (indicates strong feeling or surprise)\n",
            "': apostrophe (indicates possession or omitted letters)\n",
            "?: question mark (indicates a question)\n",
            "Overall meaning of the sentence:\n",
            "The last punctuation mark '?' suggests 'question mark (indicates a question)'.\n",
            "None\n",
            "Final Sentiment: Positive\n",
            "Sarcasm Prediction: Not a Sarcasm.\n",
            "Emoji Sentiment: Negative\n"
          ]
        }
      ],
      "source": [
        "text = \"What a beautiful day! Isn't itü•≤?\"\n",
        "final_sentiment, sarcasm_result, emoji_result = predict_sentiment_with_emoji_and_sarcasm(text)\n",
        "print(check_punctuation(text))\n",
        "print(\"Final Sentiment:\", result_list[final_sentiment])\n",
        "print(\"Sarcasm Prediction:\", sarcasm_result)\n",
        "print(\"Emoji Sentiment:\", emoji_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mrURiRP9Y3f-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8e8a9de-cc07-45d0-82be-b10e09b31270"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 39ms/step\n",
            "Punctuation marks found in the sentence:\n",
            ".: period (indicates the end of a sentence)\n",
            "!: exclamation mark (indicates strong feeling or surprise)\n",
            "!: exclamation mark (indicates strong feeling or surprise)\n",
            "Overall meaning of the sentence:\n",
            "The last punctuation mark '!' suggests 'exclamation mark (indicates strong feeling or surprise)'.\n",
            "None\n",
            "Final Sentiment: Negative\n",
            "Sarcasm Prediction: Sarcasm Detected!\n",
            "Emoji Sentiment: Positive\n"
          ]
        }
      ],
      "source": [
        "text = \"You just broke my car window. Great job!!üòÜ\"\n",
        "final_sentiment, sarcasm_result, emoji_result = predict_sentiment_with_emoji_and_sarcasm(text)\n",
        "print(check_punctuation(text))\n",
        "print(\"Final Sentiment:\", result_list[final_sentiment])\n",
        "print(\"Sarcasm Prediction:\", sarcasm_result)\n",
        "print(\"Emoji Sentiment:\", emoji_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BweWhIaX-Cfx"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Provided dataset\n",
        "punctuation_marks = ['.', ',', ';', ':', '?', '!', '-', \"'\", '\"', '(', ')', '[', ']', '{', '}', '/', '\\\\', '<', '>', '|', '*', '&', '@', '#', '%', '^', '_', '+', '=', '~', '`', '$', '&', '¬£', '‚Ç¨', '¬•', '¬¢', '¬§', '¬ß', '¬©', '¬Æ', '‚Ñ¢', '¬¨', '¬¶', '¬µ', '¬±', '√ó', '√∑', '¬¢', '‡∏ø', '‚Ç°', '‚Ç¢', '‚Ç£', '‚Ç§', '‚Ç•', '‚Ç¶', '‚Çß', '‚Ç®', '‚Ç©', '‚Ç™', '‚Ç´', '‚Ç¨', '‚Ç≠', '‚ÇÆ', '‚ÇØ', '‚Ç∞', '‚Ç±', '‚Ç≤', '‚Ç≥', '‚Ç¥', '‚Çµ', '‚Ç∂', '‚Ç∑', '‚Ç∏', '‚Çπ', '‚Ç∫', '‚Çª', '‚Çº', '‚ÇΩ', '‚Çæ', '‚Çø']\n",
        "punctuation_meanings = {\n",
        "    '.': 'period (indicates the end of a sentence)',\n",
        "    ',': 'comma (separates items in a list or series)',\n",
        "    ';': 'semicolon (indicates a pause or separates independent clauses)',\n",
        "    ':': 'colon (introduces a list or explanation)',\n",
        "    '?': 'question mark (indicates a question)',\n",
        "    '!': 'exclamation mark (indicates strong feeling or surprise)',\n",
        "    '-': 'hyphen (joins words or parts of words)',\n",
        "    \"'\": 'apostrophe (indicates possession or omitted letters)',\n",
        "    '\"': 'quotation mark (indicates speech or a quotation)',\n",
        "    '(': 'left parenthesis (encloses additional information)',\n",
        "    ')': 'right parenthesis (encloses additional information)',\n",
        "    '[': 'left square bracket (encloses additional information)',\n",
        "    ']': 'right square bracket (encloses additional information)',\n",
        "    '{': 'left curly bracket (encloses additional information)',\n",
        "    '}': 'right curly bracket (encloses additional information)',\n",
        "    '/': 'forward slash (used in URLs, paths, or fractions)',\n",
        "    '\\\\': 'backslash (used in file paths or escape characters)',\n",
        "    '<': 'less than sign (used in mathematical expressions or HTML tags)',\n",
        "    '>': 'greater than sign (used in mathematical expressions or HTML tags)',\n",
        "    '|': 'vertical bar or pipe (used in programming or to denote alternatives)',\n",
        "    '*': 'asterisk (used for multiplication, wildcard characters, or emphasis)',\n",
        "    '&': 'ampersand (represents \"and\", used in HTML or programming)',\n",
        "    '@': 'at symbol (used in email addresses or social media handles)',\n",
        "    '#': 'hashtag (used in social media to categorize topics)',\n",
        "    '%': 'percent sign (indicates a percentage)',\n",
        "    '^': 'caret (used in mathematical expressions or to denote exponentiation)',\n",
        "    '_': 'underscore (used in programming or for emphasis)',\n",
        "    '+': 'plus sign (used in mathematical expressions or to denote addition)',\n",
        "    '=': 'equal sign (indicates equality or assignment)',\n",
        "    '~': 'tilde (used in programming or as a diacritical mark)',\n",
        "    '`': 'grave accent (used in programming or as a diacritical mark)',\n",
        "    '$': 'dollar sign (used to denote currency)',\n",
        "    '¬£': 'pound sign (used to denote currency)',\n",
        "    '‚Ç¨': 'euro sign (used to denote currency)',\n",
        "    '¬•': 'yen sign (used to denote currency)',\n",
        "    '¬¢': 'cent sign (used to denote currency)',\n",
        "    '¬§': 'currency sign (used to denote currency)',\n",
        "    '¬ß': 'section sign (used in legal documents or to denote a section)',\n",
        "    '¬©': 'copyright symbol (indicates ownership of intellectual property)',\n",
        "    '¬Æ': 'registered trademark symbol (indicates a registered trademark)',\n",
        "    '‚Ñ¢': 'trademark symbol (indicates a trademark)',\n",
        "    '¬¨': 'negation symbol (used in logic or to indicate a negative)',\n",
        "    '¬¶': 'broken vertical bar (used to denote alternatives or separate clauses)',\n",
        "    '¬µ': 'micro sign (used in scientific notation or to denote micro- units)',\n",
        "    '¬±': 'plus-minus sign (indicates a range of values)',\n",
        "    '√ó': 'multiplication sign (indicates multiplication)',\n",
        "    '√∑': 'division sign (indicates division)',\n",
        "    '‡∏ø': 'baht sign (used to denote currency)',\n",
        "    '‚Ç°': 'colon sign (used to denote currency)',\n",
        "    '‚Ç¢': 'cruzeiro sign (used to denote currency)',\n",
        "    '‚Ç£': 'french franc sign (used to denote currency)',\n",
        "    '‚Ç§': 'lira sign (used to denote currency)',\n",
        "    '‚Ç•': 'mill sign (used to denote currency)',\n",
        "    '‚Ç¶': 'naira sign (used to denote currency)',\n",
        "    '‚Çß': 'peseta sign (used to denote currency)',\n",
        "    '‚Ç®': 'rupee sign (used to denote currency)',\n",
        "    '‚Ç©': 'won sign (used to denote currency)',\n",
        "    '‚Ç™': 'new sheqel sign (used to denote currency)',\n",
        "    '‚Ç´': 'dong sign (used to denote currency)',\n",
        "    '‚Ç≠': 'kip sign (used to denote currency)',\n",
        "    '‚ÇÆ': 'tugrik sign (used to denote currency)',\n",
        "    '‚ÇØ': 'drachma sign (used to denote currency)',\n",
        "    '‚Ç∞': 'german penny sign (used to denote currency)',\n",
        "    '‚Ç±': 'peso sign (used to denote currency)',\n",
        "    '‚Ç≤': 'guarani sign (used to denote currency)',\n",
        "    '‚Ç≥': 'austral sign (used to denote currency)',\n",
        "    '‚Ç¥': 'hryvnia sign (used to denote currency)',\n",
        "    '‚Çµ': 'cedi sign (used to denote currency)',\n",
        "    '‚Ç∂': 'livre tournois sign (used to denote currency)',\n",
        "    '‚Ç∑': 'spesmilo sign (used to denote currency)',\n",
        "    '‚Ç∏': 'tenge sign (used to denote currency)',\n",
        "    '‚Çπ': 'indian rupee sign (used to denote currency)',\n",
        "    '‚Ç∫': 'turkish lira sign (used to denote currency)',\n",
        "    '‚Çª': 'nordic mark sign (used to denote currency)',\n",
        "    '‚Çº': 'manat sign (used to denote currency)',\n",
        "    '‚ÇΩ': 'ruble sign (used to denote currency)',\n",
        "    '‚Çæ': 'lari sign (used to denote currency)',\n",
        "    '‚Çø': 'bitcoin sign (used to denote cryptocurrency)'\n",
        "}\n",
        "\n",
        "# Convert the dataset into a format suitable for training\n",
        "X = np.array(punctuation_marks).reshape(-1, 1)\n",
        "y = np.array([punctuation_meanings[p] for p in punctuation_marks])\n",
        "\n",
        "# Convert punctuation marks to numerical labels\n",
        "label_encoder = OneHotEncoder(sparse=False)\n",
        "X_train = label_encoder.fit_transform(X)\n",
        "\n",
        "# Model training\n",
        "classifier = LogisticRegression()\n",
        "classifier.fit(X_train, y)\n",
        "\n",
        "# Example usage within check_punctuation_ml function\n",
        "def check_punctuation_ml(punctuation):\n",
        "    # Encode the punctuation mark using the trained label encoder\n",
        "    encoded_punctuation = label_encoder.transform([[punctuation]])\n",
        "\n",
        "    # Predict the punctuation mark meaning using the trained classifier\n",
        "    predicted_meaning = classifier.predict(encoded_punctuation)[0]\n",
        "\n",
        "    # Print the results\n",
        "    print(\"Punctuation Mark:\", punctuation)\n",
        "    print(\"Predicted Meaning:\", predicted_meaning)\n",
        "\n",
        "# Example usage\n",
        "punctuation = \",\"\n",
        "check_punctuation_ml(punctuation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bwZU4YBVSDGb"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}